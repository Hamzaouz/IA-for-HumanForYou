{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement et Préparation des Données\n",
    "\n",
    "### 1.1 Importation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score\n",
    "from sklearn.linear_model import Perceptron, LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Load and Merge Data (Charger et Fusionner les Données)\n",
    "Objectif : Charger tous les fichiers CSV, puis fusionner les données sur EmployeeID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EmployeeID  EnvironmentSatisfaction  JobSatisfaction  WorkLifeBalance  Age  \\\n",
      "0           1                      3.0              4.0              2.0   51   \n",
      "1           2                      3.0              2.0              4.0   31   \n",
      "2           3                      2.0              2.0              1.0   32   \n",
      "3           4                      4.0              4.0              3.0   38   \n",
      "4           5                      4.0              1.0              3.0   32   \n",
      "\n",
      "  Attrition     BusinessTravel              Department  DistanceFromHome  \\\n",
      "0        No      Travel_Rarely                   Sales                 6   \n",
      "1       Yes  Travel_Frequently  Research & Development                10   \n",
      "2        No  Travel_Frequently  Research & Development                17   \n",
      "3        No         Non-Travel  Research & Development                 2   \n",
      "4        No      Travel_Rarely  Research & Development                10   \n",
      "\n",
      "   Education  ... PercentSalaryHike  StandardHours StockOptionLevel  \\\n",
      "0          2  ...                11              8                0   \n",
      "1          1  ...                23              8                1   \n",
      "2          4  ...                15              8                3   \n",
      "3          5  ...                11              8                3   \n",
      "4          1  ...                12              8                2   \n",
      "\n",
      "   TotalWorkingYears TrainingTimesLastYear YearsAtCompany  \\\n",
      "0                1.0                     6              1   \n",
      "1                6.0                     3              5   \n",
      "2                5.0                     2              5   \n",
      "3               13.0                     5              8   \n",
      "4                9.0                     2              6   \n",
      "\n",
      "   YearsSinceLastPromotion  YearsWithCurrManager JobInvolvement  \\\n",
      "0                        0                     0              3   \n",
      "1                        1                     4              2   \n",
      "2                        0                     3              3   \n",
      "3                        7                     5              2   \n",
      "4                        0                     4              3   \n",
      "\n",
      "   PerformanceRating  \n",
      "0                  3  \n",
      "1                  4  \n",
      "2                  3  \n",
      "3                  3  \n",
      "4                  3  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "employee_df = pd.read_csv(\"data/employee_survey_data.csv\")\n",
    "general_df = pd.read_csv(\"data/general_data.csv\")\n",
    "manager_df = pd.read_csv(\"data/manager_survey_data.csv\")\n",
    "in_time_df = pd.read_csv(\"data/in_time.csv\")\n",
    "out_time_df = pd.read_csv(\"data/out_time.csv\")\n",
    "\n",
    "# Merge employee_df and general_df on EmployeeID\n",
    "merged_df = pd.merge(employee_df, general_df, on=\"EmployeeID\", how=\"inner\")\n",
    "\n",
    "# Merge in manager_df\n",
    "merged_df = pd.merge(merged_df, manager_df, on=\"EmployeeID\", how=\"inner\")\n",
    "\n",
    "\n",
    "# Afficher un aperçu\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Drop Irrelevant Columns (Supprimer les Colonnes Inutiles)\n",
    "Objectif : Supprimer les colonnes qui n'apportent pas d'informations utiles à l'analyse.\n",
    "#### Colonnes à supprimer :\n",
    "- Over18 : Tous les employés ont plus de 18 ans.\n",
    "- EmployeeCount : Toujours égal à 1 (inutile).\n",
    "- StandardHours : Toujours égal à 8 (inutile)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EmployeeID  EnvironmentSatisfaction  JobSatisfaction  WorkLifeBalance  Age  \\\n",
      "0           1                      3.0              4.0              2.0   51   \n",
      "1           2                      3.0              2.0              4.0   31   \n",
      "2           3                      2.0              2.0              1.0   32   \n",
      "3           4                      4.0              4.0              3.0   38   \n",
      "4           5                      4.0              1.0              3.0   32   \n",
      "\n",
      "  Attrition     BusinessTravel              Department  DistanceFromHome  \\\n",
      "0        No      Travel_Rarely                   Sales                 6   \n",
      "1       Yes  Travel_Frequently  Research & Development                10   \n",
      "2        No  Travel_Frequently  Research & Development                17   \n",
      "3        No         Non-Travel  Research & Development                 2   \n",
      "4        No      Travel_Rarely  Research & Development                10   \n",
      "\n",
      "   Education  ... NumCompaniesWorked PercentSalaryHike  StockOptionLevel  \\\n",
      "0          2  ...                1.0                11                 0   \n",
      "1          1  ...                0.0                23                 1   \n",
      "2          4  ...                1.0                15                 3   \n",
      "3          5  ...                3.0                11                 3   \n",
      "4          1  ...                4.0                12                 2   \n",
      "\n",
      "  TotalWorkingYears TrainingTimesLastYear  YearsAtCompany  \\\n",
      "0               1.0                     6               1   \n",
      "1               6.0                     3               5   \n",
      "2               5.0                     2               5   \n",
      "3              13.0                     5               8   \n",
      "4               9.0                     2               6   \n",
      "\n",
      "   YearsSinceLastPromotion  YearsWithCurrManager  JobInvolvement  \\\n",
      "0                        0                     0               3   \n",
      "1                        1                     4               2   \n",
      "2                        0                     3               3   \n",
      "3                        7                     5               2   \n",
      "4                        0                     4               3   \n",
      "\n",
      "   PerformanceRating  \n",
      "0                  3  \n",
      "1                  4  \n",
      "2                  3  \n",
      "3                  3  \n",
      "4                  3  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# Supprimer les colonnes inutiles\n",
    "columns_to_drop = [\"EmployeeCount\", \"Over18\", \"StandardHours\"]\n",
    "merged_df.drop(columns=columns_to_drop, axis=1, inplace=True, errors=\"ignore\")\n",
    "# Visualiser apres suppression de quelques colonnes\n",
    "print(merged_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Clean up and Prepare Time Data (Nettoyage et Préparation des Données de Temps)\n",
    "Objectif : Transformer les fichiers in_time et out_time pour obtenir le nombre d'heures travaillées.\n",
    "\n",
    "#### Actions :\n",
    "- Convertir les dates en format datetime.\n",
    "- Calculer la durée travaillée chaque jour (out_time - in_time).\n",
    "- Calculer la moyenne des heures travaillées pour chaque employé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EmployeeID  AverageWorkHours\n",
      "0           1          7.373651\n",
      "1           2          7.718969\n",
      "2           3          7.013240\n",
      "3           4          7.193678\n",
      "4           5          8.006175\n"
     ]
    }
   ],
   "source": [
    "# Rename 'Unnamed: 0' to 'EmployeeID' for easier merging\n",
    "in_time_df.rename(columns={\"Unnamed: 0\": \"EmployeeID\"}, inplace=True)\n",
    "out_time_df.rename(columns={\"Unnamed: 0\": \"EmployeeID\"}, inplace=True)\n",
    "\n",
    "# We’ll create a separate DataFrame that holds each employee’s average work hours\n",
    "# Convert time columns to datetime (ignore errors if any NaNs or incorrect formats appear)\n",
    "time_cols = in_time_df.columns[1:]  # skip EmployeeID column\n",
    "in_time_df[time_cols] = in_time_df[time_cols].apply(pd.to_datetime, errors=\"coerce\")\n",
    "out_time_df[time_cols] = out_time_df[time_cols].apply(pd.to_datetime, errors=\"coerce\")\n",
    "\n",
    "# Calculate the daily hours as OUT - IN\n",
    "# This returns a DataFrame of timedeltas; convert to hours by dividing total_seconds by 3600\n",
    "daily_hours = out_time_df[time_cols].sub(in_time_df[time_cols])\n",
    "daily_hours = daily_hours.apply(lambda row: row.dt.total_seconds() / 3600)\n",
    "\n",
    "# Create average hours feature per employee\n",
    "avg_hours_df = pd.DataFrame({\n",
    "    \"EmployeeID\": in_time_df[\"EmployeeID\"],\n",
    "    \"AverageWorkHours\": daily_hours.mean(axis=1)  # mean across all days\n",
    "})\n",
    "\n",
    "# Merge avg_hours_df with merged_df\n",
    "merged_df = pd.merge(merged_df, avg_hours_df, on=\"EmployeeID\", how=\"left\")\n",
    "\n",
    "print(merged_df[[\"EmployeeID\", \"AverageWorkHours\"]].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Merge Time Features Back (Fusionner les Données de Temps dans le Dataset Principal)\n",
    "**Objectif** : Ajouter la colonne AverageWorkHours au dataset fusionné."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EmployeeID  EnvironmentSatisfaction  JobSatisfaction  WorkLifeBalance  Age  \\\n",
      "0           1                      3.0              4.0              2.0   51   \n",
      "1           2                      3.0              2.0              4.0   31   \n",
      "2           3                      2.0              2.0              1.0   32   \n",
      "3           4                      4.0              4.0              3.0   38   \n",
      "4           5                      4.0              1.0              3.0   32   \n",
      "\n",
      "  Attrition     BusinessTravel              Department  DistanceFromHome  \\\n",
      "0        No      Travel_Rarely                   Sales                 6   \n",
      "1       Yes  Travel_Frequently  Research & Development                10   \n",
      "2        No  Travel_Frequently  Research & Development                17   \n",
      "3        No         Non-Travel  Research & Development                 2   \n",
      "4        No      Travel_Rarely  Research & Development                10   \n",
      "\n",
      "   Education  ... StockOptionLevel TotalWorkingYears  TrainingTimesLastYear  \\\n",
      "0          2  ...                0               1.0                      6   \n",
      "1          1  ...                1               6.0                      3   \n",
      "2          4  ...                3               5.0                      2   \n",
      "3          5  ...                3              13.0                      5   \n",
      "4          1  ...                2               9.0                      2   \n",
      "\n",
      "  YearsAtCompany YearsSinceLastPromotion  YearsWithCurrManager  \\\n",
      "0              1                       0                     0   \n",
      "1              5                       1                     4   \n",
      "2              5                       0                     3   \n",
      "3              8                       7                     5   \n",
      "4              6                       0                     4   \n",
      "\n",
      "   JobInvolvement  PerformanceRating  AverageWorkHours_x  AverageWorkHours_y  \n",
      "0               3                  3            7.373651            7.373651  \n",
      "1               2                  4            7.718969            7.718969  \n",
      "2               3                  3            7.013240            7.013240  \n",
      "3               2                  3            7.193678            7.193678  \n",
      "4               3                  3            8.006175            8.006175  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# Fusionner les données de temps avec le dataset principal\n",
    "final_df = pd.merge(merged_df, avg_hours_df, on=\"EmployeeID\", how=\"left\")\n",
    "\n",
    "# Vérifier les mises à jour\n",
    "print(final_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6 Create or Transform Other Meaningful Features (Créer ou Transformer des Variables Intéressantes)\n",
    "**Objectif** : Transformer les variables en formats exploitables pour l’analyse et les modèles.\n",
    "\n",
    "#### Transformations importantes :\n",
    "Encodage de Attrition : Convertir Yes/No en 1/0.\n",
    "Remplacer les valeurs manquantes (NA) dans employee_survey_data.csv par la médiane.\n",
    "Encodage des variables catégorielles (BusinessTravel, EducationField, etc.).\n",
    "Création d'une variable YearsSinceLastPromotionRatio : YearsSinceLastPromotion / YearsAtCompany."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EmployeeID  EnvironmentSatisfaction  JobSatisfaction  WorkLifeBalance  Age  \\\n",
      "0           1                      3.0              4.0              2.0   51   \n",
      "1           2                      3.0              2.0              4.0   31   \n",
      "2           3                      2.0              2.0              1.0   32   \n",
      "3           4                      4.0              4.0              3.0   38   \n",
      "4           5                      4.0              1.0              3.0   32   \n",
      "\n",
      "   Attrition              Department  DistanceFromHome  Education  JobLevel  \\\n",
      "0          0                   Sales                 6          2         1   \n",
      "1          1  Research & Development                10          1         1   \n",
      "2          0  Research & Development                17          4         4   \n",
      "3          0  Research & Development                 2          5         3   \n",
      "4          0  Research & Development                10          1         1   \n",
      "\n",
      "   ...  MaritalStatus_Single  JobRole_Human Resources  \\\n",
      "0  ...                 False                    False   \n",
      "1  ...                  True                    False   \n",
      "2  ...                 False                    False   \n",
      "3  ...                 False                     True   \n",
      "4  ...                  True                    False   \n",
      "\n",
      "   JobRole_Laboratory Technician  JobRole_Manager  \\\n",
      "0                          False            False   \n",
      "1                          False            False   \n",
      "2                          False            False   \n",
      "3                          False            False   \n",
      "4                          False            False   \n",
      "\n",
      "   JobRole_Manufacturing Director  JobRole_Research Director  \\\n",
      "0                           False                      False   \n",
      "1                           False                      False   \n",
      "2                           False                      False   \n",
      "3                           False                      False   \n",
      "4                           False                      False   \n",
      "\n",
      "   JobRole_Research Scientist  JobRole_Sales Executive  \\\n",
      "0                       False                    False   \n",
      "1                        True                    False   \n",
      "2                       False                     True   \n",
      "3                       False                    False   \n",
      "4                       False                     True   \n",
      "\n",
      "   JobRole_Sales Representative  YearsSinceLastPromotionRatio  \n",
      "0                         False                      0.000000  \n",
      "1                         False                      0.166667  \n",
      "2                         False                      0.000000  \n",
      "3                         False                      0.777778  \n",
      "4                         False                      0.000000  \n",
      "\n",
      "[5 rows x 42 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fallo\\AppData\\Local\\Temp\\ipykernel_22244\\4004663908.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  final_df[col].fillna(final_df[col].median(), inplace=True)\n",
      "C:\\Users\\fallo\\AppData\\Local\\Temp\\ipykernel_22244\\4004663908.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  final_df[col].fillna(final_df[col].median(), inplace=True)\n",
      "C:\\Users\\fallo\\AppData\\Local\\Temp\\ipykernel_22244\\4004663908.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  final_df[col].fillna(final_df[col].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Transformer la colonne 'Attrition' en variable binaire\n",
    "final_df[\"Attrition\"] = final_df[\"Attrition\"].map({\"No\": 0, \"Yes\": 1})\n",
    "\n",
    "# Remplacer les valeurs manquantes par la médiane dans employee_survey_data\n",
    "for col in [\"EnvironmentSatisfaction\", \"JobSatisfaction\", \"WorkLifeBalance\"]:\n",
    "    final_df[col].fillna(final_df[col].median(), inplace=True)\n",
    "\n",
    "# Encodage des variables catégorielles avec pandas get_dummies\n",
    "final_df = pd.get_dummies(final_df, columns=[\"BusinessTravel\", \"EducationField\", \"Gender\", \"MaritalStatus\", \"JobRole\"], drop_first=True)\n",
    "\n",
    "# Créer une variable 'YearsSinceLastPromotionRatio'\n",
    "final_df[\"YearsSinceLastPromotionRatio\"] = final_df[\"YearsSinceLastPromotion\"] / (final_df[\"YearsAtCompany\"] + 1)\n",
    "\n",
    "# Vérifier les mises à jour\n",
    "print(final_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des Données\n",
    "### 1. Gestion des valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnvironmentSatisfaction         0\n",
       "JobSatisfaction                 0\n",
       "WorkLifeBalance                 0\n",
       "NumCompaniesWorked              0\n",
       "TotalWorkingYears               0\n",
       "AverageWorkHours_x              0\n",
       "AverageWorkHours_y              0\n",
       "YearsSinceLastPromotionRatio    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vérifier les valeurs manquantes\n",
    "df.isnull().sum()\n",
    "\n",
    "# Imputer les valeurs manquantes pour les variables numériques avec la médiane\n",
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "# Sélection des colonnes numériques\n",
    "\n",
    "## à Compléter\n",
    "df_num = df.select_dtypes(include=float)\n",
    "imputer.fit(df_num)\n",
    "## à Compléter\n",
    "\n",
    "# Remplacement des valeurs manquantes\n",
    "df_num_imputed = pd.DataFrame(imputer.transform(df_num), columns=df_num.columns)\n",
    "\n",
    "# Vérifier s'il reste des valeurs manquantes\n",
    "df_num_imputed.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Encodage des variables catégorielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Department_Human Resources</th>\n",
       "      <th>Department_Research &amp; Development</th>\n",
       "      <th>Department_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Department_Human Resources  Department_Research & Development  \\\n",
       "0                       False                              False   \n",
       "1                       False                               True   \n",
       "2                       False                               True   \n",
       "3                       False                               True   \n",
       "4                       False                               True   \n",
       "\n",
       "   Department_Sales  \n",
       "0              True  \n",
       "1             False  \n",
       "2             False  \n",
       "3             False  \n",
       "4             False  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sélection des colonnes catégorielles\n",
    "df_cat = df.select_dtypes(include=[object])\n",
    "\n",
    "# Encodage one-hot des variables catégorielles\n",
    "\n",
    "## à Compléter\n",
    "df_cat_encoded = pd.get_dummies(df_cat)\n",
    "## à Compléter \n",
    "\n",
    "# Vérification du résultat de l'encodage\n",
    "df_cat_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Normalization des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Assemblage des données préparées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Séparation des caractéristiques (X) et de la cible (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration et Visualisation des Données\n",
    "\n",
    "### 1. Analyse des Statistiques Descriptives\n",
    "\n",
    "Avant de plonger dans la visualisation des données, examinons les statistiques descriptives pour obtenir une première idée des distributions des variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Tests d'ANOVA & X2\n",
    "write something"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Visualisation des Variables Numériques\n",
    "Nous commencerons par visualiser les distributions des variables numériques pour mieux comprendre leurs comportements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Matrice de Corrélation\n",
    "Pour explorer les relations entre les variables numériques, nous utilisons une matrice de corrélation et une heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Visualisation des Relations entre les Variables\n",
    "Nous allons créer quelques graphes de dispersion pour visualiser les relations entre certaines variables clés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Analyse de la Variable Cible\n",
    "Analysons la variable cible Sold6M pour voir comment elle est distribuée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Relations entre les Variables et la Cible\n",
    "Examinons comment certaines variables influencent la probabilité de vendre un bien immobilier dans les 6 mois."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modèles de Classification\n",
    "Dans cette section, nous allons créer et évaluer plusieurs modèles de classification afin de prédire... (ici on met des definitions rapide et insights sur les modeles (interpretabilité vs performance...))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application des modèles\n",
    "### 0. Préparation des données d'apprentissage et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Régerssion Logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, ajouter plusieurs cellules (entrainement, evaluation, optimisation, explicabilité)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, ajouter plusieurs cellules (entrainement, evaluation, optimisation, explicabilité)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etude comparative entre les modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interprétation des Résultats\n",
    "### 1. Analyse des Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "### 1. Synthèse des Travaux Réalisés"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
